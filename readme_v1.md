# Analyser project v2

## old version

see readmev0.md 

many problem occured (concurency, exploiting data,monolith) so a new version mod oriented to handle different part of program

## architecture plan

main2.py : should run the overlay/ui part and launch (and leave properly) other server needed

dockerise ? we may need to dockerise the app to handle (run and quit) server and port

each part of pgm will have dedicated port to send/recieve data 

## effective architecture

right now here is what is implemented :
overlay_socket.py (listen on 5002), handler.py (5000), server_cv.py (5001), main2.py

### overlay

overlay_socket.py is the overlay used while overlay.py was the first version that wasn't set up to interact with a handler

overlay_socket create a socket to recieve data from the flask handler. and it send it to the handler after capturing a the window via requests.

it work with two listener one on keyboard and the other on mouse. when ctrl is capture it wait for two click that are used to get the coordonate of the frame to capture.

get active window was primarly used to detect window change (as capture was primarly triggered by the change) however it will be usefull to get information about the window to process data . will see that further

done :ctrl event actually have a critical bug. Need to review the loop !!!

overlay_test is used to develop feature on overlay while not touching to the working structure of overlay.

to dev :
almost all feature , an object that allow to recieve data from the various server, a menu to customize setting, hide and block (not sensitive to key/mouse event) option, 

an option to make the overlay sensitive to event (click)

two shortcut are implemented:
ctrl+esc = quit 

ctrl + alt = action
(this shortcut wait for another key)
m : change mod
c : capture (wait for 2 clicks)

### handler

the handler is the core of the app : 

- recieve image from overlay at process_image adress and trasmit it to the open cv server
- recieve text from open_cv_server at cv_txt adress and right now send it to the overlay via send_data_to_overlay function using socket (that avoid conflict with flask in overlay)

to dev : 
should implement the call to the llm with (extract_v3.py ? structure)
custom prompt , 
status code 
and error handling


### server_cv.py


recieve image at /trt_image and send back text to handler 

to dev : handle image trt to extract object

### main2.py

contain a fonction to empty directory : need to be edited manually right now (could be upgrade by argparse ...)

to dev : launch all server using a setting file
... to think


## to dev apart from the existing feature

setting.json (to get the port, available server, prompt used, control setting for the capture, setting for the overlay and control flow) 
    => almost done
main.sh (generated by main.py?) or docker-compose (with a docker file for each server) to monitor the whole app
detailled prompts for the llm process (clean data/correct sentence, extract info) => prototype
logging utils 

cross checking facts (see post of gael penessot about scrapping ?)
integrate dbs (vector? and classic (nosql or sql ?)) to store data (img,text,report...) and maybe train a model ?
make a parralelle process of the llm treatment (tf-idf,sentiment analysis...)
make model to train : analitics(getting info from text and posts),predictive (about reaction to the post ?),descional (making reasearch about a subject or not (to cross validate ...))

# issue detected

the prompt must not contain ' " ' symbol which is a several issue ...
fonction are too complex (capture window ...) => single responsability should be applied and call a process that orchestrate functions.
change addr 0.0.0.0 is not a good practice !!! (opening to all interface wifi,local...) => 127.0.0.1 ! 

really long time of answering for the llm !!! (dev analyse which is made for analisys brick by brick (aka sentiment,...) so the result should be faster)
handle synchronicity between program part to be more consistent (asyncio/threading/not blocking ui)